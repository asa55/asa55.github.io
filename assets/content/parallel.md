# Parallel Processing

This is the only section on this site that is a direct summation of my notes from a recent coding bootcamp, offered as an 8-hour onsite workshop featuring some Nvidia's own expert staff!

## Python CUDA and Numba

Check out NVIDIA's [Deep Learning Institute!](https://www.nvidia.com/en-us/deep-learning-ai/education/)

## Elementwise Operations

    Use Numba to compile Python functions for the CPU.
    Understand how Numba compiles Python functions.
    GPU accelerate NumPy ufuncs.
    GPU accelerate hand-written vectorized functions.
    Optimize data transfers between the CPU host and GPU device.


## 1-D Operations

* Write custom CUDA kernels in Python and launch them with an execution configuration.
* Utilize grid stride loops for working in parallel over large data sets and leveraging memory coalescing.
* Use atomic operations to avoid race conditions when working in parallel.

## 2-D Operations
